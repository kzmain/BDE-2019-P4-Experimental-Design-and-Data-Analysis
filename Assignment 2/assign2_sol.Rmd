---
title: "Assignment 2"
author: "Sherida van den Bent, Chang Liu, Kai Zhang"
date: "2020/03/10"
output: pdf_document
---
```{r echo=FALSE,,message=FALSE}
set.seed(1234)
library("car")
library("lme4")
```
## Exercise 1
**a)**
In this experiment, we have two factors: environment and humidity. Environment has a fixed level of $\textit{I} = 3$, and humidity has a fixed level of $\textit{J} = 2$. Furthermore, we have 18 experimental units, and because balanced design is a common choice, we choose $\textit{N} = 18 \div \textit{I} \div \textit{J} = 3$. We use 1, 2, 3 in the first row (the environment) to represent cold, intermediate, and warm respectively. In the second row (humidity), we use 1 and 2 to represent dry and wet. The third row is the unit index, ranging from 1 to 16. Each column represents a combination of environment, humidity, and experimental unit.
```{r}
I=3; J=2; N=3
rbind(rep(1:I,each=N*J),rep(1:J,N*I),sample(1:(N*I*J)))
```
For unit 16 we use levels ('cold','dry'); for unit 5 we use levels ('cold','wet'); . . .; for unit 1 we use levels ('warm','wet').

**b)**
```{r}
bread = read.table('bread.txt')
par(mfrow=c(1,2))
boxplot(hours~environment, data=bread); boxplot(hours~humidity, data=bread);
interaction.plot(bread$environment,bread$humidity,bread$hours); interaction.plot(bread$humidity,bread$environment,bread$hours)
```
From the box plot, we can see that `intermediate` and `warm` have a similar decay time, and `cold` can greatly increase decay time. Futhermore, the median time value of `dry` is bigger than the median time value of `wet`.
From the interaction lines we can see that there is an interaction between the ennvironment and the humidity.

**c)**
In this analysis there is no mixed effect, so only fixed effects analysis will be conducted.
```{r}
bread = read.table('bread.txt')
bread$environment=factor(bread$environment); bread$humidity=factor(bread$humidity) 
breadlm=lm(hours~environment*humidity, data=bread); 
anova(breadlm)
```
Our interest is in the main and interaction effects of the outer and inner factor. The main effects for environment and humidity are significant, at the same time the p-value of testing: $H_0 : \gamma_{i,j} = 0$ for all (i, j) is 3.705e-07, which means that interaction effect is highly significant; in other words, the bread decay times are related to the effects between the humidity and the environment. If the humidity does not change, but the environment changes, then the decay time changes as well. If the environment does not change, but the humidity changes, so does the decay time.

**d)**
This is not a good question. The reason for this is as follows. From the summary shown in the previous question we also can see interaction effect is highly significant; we should NOT interpret the main effects without considering the interaction effect.

**e)**
```{r}
par(mfrow=c(2,2))
plot(breadlm, 2); plot(breadlm, 1)
shapiro.test(residuals(object = breadlm))
```
First we need to check the assumption: normal distribution of the model residuals. After creating a QQ-plot, we cannot tell whether it is a normal distribution because of some outliers. Therefore we also use the Shapiro-Wilk normality test. Based on the p-value(0.1911 > 0.05), we could say that it is probably normally distributed. Our conclusion: the first assumption of normal distribution of the model residuals has been met.
The fitted plot seems to indicate that the residuals and the fitted values are uncorrelated. Our conclusion: the second assumption of homogeneity of variance of the groups has been met. There are three outliers showed in the plot: NO.5, NO.7 and NO.8.

## Exercise 2
**a)**
In this experiment, we have two factor interface and skill. The treatment factor interface has a fixed level of $\textit{I} = 3$, and the block variable skill has a fixed level of $\textit{B} = 5$. Also, we have 15 experimental units, and because of balanced design, we choose $\textit{N} = 15 \div \textit{I} \div \textit{J} = 1$.
```{r}
I=3; B=5; N=1
for (i in 1:B) print(sample(1:15)[(I*(i-1) + 1):(I*(i-1) + 3)])
```
For block 1 we assign unit 4 to treatment 1, unit 15 to treatment 2, etc., for block 2 assign unit 12 to treatment 1, unit 3 to treatment 2, etc.

**b)**
```{r}
search = read.table('search.txt')
search$skill=as.factor(search$skill); search$interface=as.factor(search$interface);
attach(search); par(mfrow=c(2,2))
boxplot(time~interface); boxplot(time~skill);
interaction.plot(interface,skill,time); interaction.plot(skill,interface,time);
```
From looking at the boxplot, we can see that factors do have some effect. 
From looking at the interaction plot, the lines in interaction plot are roughly parallel; therefore we can say there are no interactions between interface and skill.

**c)**
```{r results='hide'}
searchaov=lm(time~interface+skill, data=search)
anova(searchaov)
```
The p-value for testing $H_{0}:\alpha_{i}=0$ for all $\textit(i)$ is 0.01310. Conclusion: reject $H_{0}$ and search time is not the same for all interfaces.
```{r results='hide'}
summary(searchaov)
15.013+2.700+3.033
```
The estimate value for $\hat{\mu}$=15.013, $\hat{\alpha_2}$=2.700, $\hat{\beta_3}$=3.033. So the the estimated time for the given factors is $\hat{\mu_{23}}=\hat{\mu}+\hat{\alpha_2}+\hat{\beta_3}$=20.746.

**d)**
```{r results='hide'}
par(mfrow=c(1,2)); plot(searchaov, 2); plot(searchaov, 1)
shapiro.test(residuals(object = searchaov))
```
First we need to check the assumption: normal distribution of the model residuals. After creating a QQ-plot, we cannot tell whether it is normal distribution because of some outliers. So we also use the Shapiro-Wilk normality test. Based on the p-value(0.2817 > 0.05), we could say it probably normal distributed. Conclusion: the first assumption of normal distribution of the model residuals has been met.
The fitted plot seems to indicate that the residuals and the fitted values are uncorrelated. Conclusion: the second assumption of homogeneity of variance of the groups has been met.

**e)**
```{r}
attach(search); friedman.test(time, interface, skill)[[3]]
```
p-value for testing $H_{0}$ : no treatment effect is 0.04076, so $H_{0}$ is rejected, there is an effect of interface.

**f)**
```{r}
searchoneaov = lm(time ~ interface, data = search)
anova(searchoneaov)
```
It is not useful to perform this test on this dataset, because randomized block design is to make the variability within blocks less than the variability between blocks, and this design reduces variability within treatment conditions and potential confounding, producing a better estimate of treatment effects. Since we already gathered enough data, we should apply the randomized block design instead of one-way ANOVA.

## Exercise 3
**a)**
```{r}
cow=read.table("cow.txt",header=TRUE,sep=" ");
cow$id=factor(cow$id); cow$per=factor(cow$per)
cowlm=lm(milk~treatment+per+id,data=cow); anova(cowlm)
par(mfrow=c(1,2)); plot(cowlm, 2); plot(cowlm, 1)
```
Before making any conclusion, we should check the assumption of ANOVA. The result seems fine, and we can rely on the result. The sequence effect is left out, because it cannot be estimated in a fixed effects model. We do not have enough information to estimate all effects as fixed effects from the available data. In the mixed effects model this is possible. 
```{r}
summary(cowlm)
```
The p-value for treatment is 0.75147. There is no evidence that feedingstuffs are different and the negative feedingstuffs gives 0.5100 less milk production. Furthermore, the p-value of testing: $H_0 : \gamma_{psn} = 0$ for all (psn) is 0.015046, which means learning (=per) effect is highly significant.

**b)**
```{r}
library(lme4); attach(cow)
cowlmer=lmer(milk~treatment+order+per+(1|id),REML=FALSE) 
summary(cowlmer)
```
The estimated treatment and period effects under fixed effects are identical to those in the previous `lm()`'s results. The negative feedingstuffs gives 0.5100 less milk production.
```{r}
cowlmer1=lmer(milk~order+per+(1|id),REML=FALSE) 
anova(cowlmer1,cowlmer)
```
As illusstrated for treatment, there is no significicant effect.

**c)**
```{r}
attach(cow)
t.test(milk[treatment=="A"],milk[treatment=="B"],paired=TRUE)
```
No, it is not a valid test for a difference in milk production. This is because when we use t-test for seeing effects, we assume that there is no order effect; but we previously concluded that there is an order effect.
Its conclusion is compatible with the one obtained in a, because the result in a) is fixed effect analysis, it does not consider the order effect so does `t.test()` in this question. So the p-value for treatment is identical to the reuslt found in a). The p-value for id is not interesting.

## Exercise 4
**a)**
```{r}
nausea = read.table('nauseatable.txt')
df = data.frame(matrix(0,304,2))
names(df) <- c("naus", "medicin")
df[1:180, 1] = 1; df[181: 304, 1] = 2
df[1:100, 2] = 1; df[101:132, 2] = 2; df[133:180, 2] = 3
df[181:232, 2] = 1; df[233:267, 2] = 2; df[268:304, 2] = 3
xtabs(~medicin+naus, data=df)
```
We use number 1 in column "naus" to indicate "Incidence of no nausea", number 2 to indicate "Incidence of Nausea". Number 1 in column 'medicin' to indicate "Chlorpromazine" and 2, 3 for "Pentobarbital(100mg)", "Pentobarbital(150mg)" respectively. xtabs are a convenient function to creat contingency table, so the result is same as the data in "nauseatable.txt".

**b)**
```{r}
B=1000
tstar=numeric(B)
for (i in 1:B) {
  treatstar=df
  treatstar[,2] = sample(df[,2])
  tstar[i] = chisq.test(xtabs(~medicin+naus, data = treatstar))[[1]]
}
myt = chisq.test(xtabs(~medicin+naus, data = df))[[1]]
pr=sum(tstar>myt)/B
pr
```
The p-value for testing $H_{0}: $the different medicines work equally well against nausea is 0.031. Conclusion:  we reject $H_{0}$ and we have confidence that there exists difference between the different medicines.

**c)**
```{r}
chisq.test(xtabs(~medicin+naus, data = df))[[3]]
```
The p-value from permutation test and chi-square test for contingency tables are very close.

## Exercise 5
**a)**
5.a graphical summaries
```{r}
expensescrime=read.table("expensescrime.txt",header=TRUE,sep=" ");
plot(expensescrime[,c(2,3,4,5,6,7)]);par(mfrow=c(2,3));
for (i in c(2,3,4,5,6,7)) hist(expensescrime[,i],main=names(expensescrime)[i])
```
From the histogram graphs, we can see that the features `bad`, `lawyers`, `employ`, `pop` have similar shapes, so there is a highly collinearity problem in linear regression.

Potential points
A potential point is an observation with an outlying value in an explanatory variable $X_i$. As it shows in the histogram, there are some extreme values in the `bad`, `lawyers`, `employ`, `pop` columns when X is very big, so it has potential points.

Influence points 
We will use Cook's distance and draw the corresponding plot chart to investigate influence points between expense data and other data. If the Cook's distance is bigger than 1, then it is considered to be an influence point.
```{r}
expenselm=lm(expend~bad+crime+lawyers+employ+pop, data=expensescrime);
plot(1:51,cooks.distance(expenselm),type="b"); 
```
```{r results='hide'}
cooks.distance(expenselm)
```
According to model expense~bad+crime+lawyers+employ+pop, we got 4 inluence points in the following way:
    * Point 5 is an influence point, it's Cook distance is 4.91 > 1.
    * Point 8 is an influence point, it's Cook distance is 3.51 > 1.
    * Point 35 is an influence point, it's Cook distance is 1.09 > 1.
    * Point 44 is an influence point, it's Cook distance is 2.70 > 1.
    
Collinearity
We will use the variance inflation factor (VIF) to investigate potential collinearity in the dataset, for the $\beta_j$ in model Y_n=$\beta_0+\beta_1X_{n1}+\beta_2X_{n2}+…+\beta_pX_{np}+e_n, n=1,2,…,N$,if the $\beta_j$'s VIF is bigger than 5, then it is considered  $\beta_j$ is unreliable.
```{r}
expensescrimelm=lm(expend~bad+crime+lawyers+employ+pop, data=expensescrime) 
vif(expensescrimelm) 
```
```{r}
expensescrimelm2=lm(expend~crime+lawyers+employ+pop, data=expensescrime) 
vif(expensescrimelm2) 
```
```{r}
expensescrimelm3=lm(expend~crime+employ+pop, data=expensescrime) 
vif(expensescrimelm3) 
```
```{r}
expensescrimelm4=lm(expend~crime+pop, data=expensescrime) 
vif(expensescrimelm4) 
```
```{r}
expensescrimelm5=lm(expend~crime, data=expensescrime) 
```
In the 1st model to 3rd model, only 1 out of 5 VIF is lower than 5, so there are collinearity problems in those models.
The last 2 models are ok with respect to collinearity problems. 

**b)**
We use the summary function, and its 8th output is the $R^2$ determination coefficient. We don't print all the results, but the p-value here is equality important.
First we use the step-up method.
```{r results='hide'}
summary(lm(expend~bad,data=expensescrime))[[8]]
summary(lm(expend~crime,data=expensescrime))[[8]]
summary(lm(expend~lawyers,data=expensescrime))[[8]]
summary(lm(expend~pop,data=expensescrime))[[8]]
```
```{r}
summary(lm(expend~employ,data=expensescrime))[[8]]
```
The model expend~employ has max determination coefficient: 0.954, so we chose this model for the next step.
```{r results='hide'}
summary(lm(expend~employ+bad,data=expensescrime))[[8]]
summary(lm(expend~employ+crime,data=expensescrime))[[8]]
summary(lm(expend~employ+pop,data=expensescrime))[[8]]
```
```{r}
summary(lm(expend~employ+lawyers,data=expensescrime))[[8]]
```
In those four models only `lawyers` in expend~employ+lawyers is significant (p-value=0.00113 < 0.05), and it has determination coefficient 0.9632, larger than 0.954, so we chose this model for thenext step.
```{r results='hide'}
summary(lm(expend~employ+lawyers+bad,data=expensescrime))[[8]]
summary(lm(expend~employ+lawyers+crime,data=expensescrime))[[8]]
summary(lm(expend~employ+lawyers+pop,data=expensescrime))[[8]]
```
All of those newly added features yield insignificant explanatory variables, so we can stop and take the model expend~employ+lawyers as our final step-up model.
Then we use the step-up method.
```{r results='hide'}
summary(lm(expend~bad+crime+lawyers+employ+pop,data=expensescrime))
```
Feature `crime` has the largest p-value 0.25534, and it is larger than 0.05, so we remove crime from the model.
```{r results='hide'}
summary(lm(expend~bad+lawyers+employ+pop,data=expensescrime))
```
Feature pop has the largest p-value 0.06012, and it is larger than 0.05, so we remove pop from the model.
```{r results='hide'}
summary(lm(expend~bad+lawyers+employ,data=expensescrime))
```
Feature bad has the largest p-value 0.34496, and it is larger than 0.05, so we remove bad from the model.
```{r results='hide'}
summary(lm(expend~lawyers+employ,data=expensescrime))
```
All remaining explanatory variables in the model are significant, so we can stop and take model expend~employ+lawyers as our final step-up model. Both method generate the same model: expend~employ+lawyers.

**c)**
(1)Scatter plot: plot residuals against each X_k  in the model separately
```{r}
attach(expensescrime); expendlm=lm(expend~lawyers+employ)
par(mfrow=c(1,2)); plot(residuals(expendlm),lawyers); plot(residuals(expendlm),employ) 
```
There are V curve shown in two charts, include $lawyers^2$ and $employ^2$
```{r warning=FALSE}
expensescrime$lawyers2=expensescrime$lawyers^2
expensescrime$employ2=expensescrime$employ^2
expendlm2=lm(expend~expend+lawyers+lawyers2+employ+employ2,data=expensescrime)
par(mfrow=c(1,2)); plot(residuals(expendlm2),lawyers); plot(residuals(expendlm2),employ) 
summary(expendlm2)
```
There is no specific curved pattern visible, good!

(2)normal QQ-plot of the residuals
```{r}
plot(expendlm2, 2)
shapiro.test(residuals(expendlm2))
```
From looking at the QQ-plot we can not see if it is a normal distribution. We did the Shapiro-Wilk normality test, and we got p-value 0.001464 < 0.05, which means it is normally distributed.